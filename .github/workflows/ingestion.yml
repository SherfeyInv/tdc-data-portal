name: Daily Scraping Job

on:
  schedule:
    - cron: '0 0 1 1 0'  # This cron expression runs the workflow at midnight UTC every year 1st January
  workflow_dispatch:  # This allows manual trigger

jobs:
  scrape-data:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.8'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r src/ckanext-tdc/ckanext/tdc/data-ingestion/requirements.txt  # Make sure you have a requirements.txt file

      - name: Run GFEI ingestion
        env:
          API_KEY: ${{ secrets.API_KEY }}
          CKAN_URL: ${{ secrets.CKAN_URL }}
        run: |
          python src/ckanext-tdc/ckanext/tdc/data-ingestion/data_ingestion_gfei.py

      - name: Run EUROSTAT ingestion
        env:
          API_KEY: ${{ secrets.API_KEY }}
          CKAN_URL: ${{ secrets.CKAN_URL }}
        run: |
          python src/ckanext-tdc/ckanext/tdc/data-ingestion/data_ingestion_eurostat.py

      - name: Run JRC ingestion
        env:
          API_KEY: ${{ secrets.API_KEY }}
          CKAN_URL: ${{ secrets.CKAN_URL }}
        run: |
          python src/ckanext-tdc/ckanext/tdc/data-ingestion/data_ingestion_jrc.py
